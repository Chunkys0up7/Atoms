id: DES-005
type: design
title: AI-Powered Impact Analysis with Claude
summary: Design for Claude API integration following claude.md guidelines for PR analysis and impact scoring
content: |
  # Claude AI Integration Design

  ## Architecture (Following claude.md)
  ```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  GitHub PR   â”‚
  â”‚   Webhook    â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  GitHub Actions  â”‚
  â”‚   Workflow       â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Python Script    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Claude API      â”‚
  â”‚ claude_helper.py â”‚â—€â”€â”€â”€â”€â”€â”‚  (Anthropic)     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Analysis Result
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PR Comment      â”‚
  â”‚  (via GitHub API)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ```

  ## Safety Constraints (per claude.md)

  ### 1. No PII or Sensitive Data
  ```python
  def sanitize_atom_for_ai(atom: dict) -> dict:
      """Remove sensitive fields before sending to Claude."""
      return {
          'id': atom['id'],
          'type': atom['type'],
          'title': atom['title'],
          'summary': atom['summary'][:200],  # Truncate
          'metadata': {
              'priority': atom['metadata']['priority'],
              'status': atom['metadata']['status']
          },
          # NEVER include: full content, owner emails, internal URLs
      }
  ```

  ### 2. Deterministic Output (Temperature 0)
  ```python
  import anthropic

  client = anthropic.Anthropic(api_key=os.environ['CLAUDE_API_KEY'])

  def call_claude(prompt: str) -> dict:
      message = client.messages.create(
          model="claude-sonnet-4-5-20250929",
          max_tokens=1024,
          temperature=0.0,  # Deterministic for CI
          messages=[{"role": "user", "content": prompt}]
      )

      return parse_response(message.content[0].text)
  ```

  ### 3. Context Size Limit
  ```python
  MAX_TOKENS = 4000  # Conservative limit

  def build_context(atoms: list[dict], pr_data: dict) -> str:
      """Build truncated context for Claude."""
      context = {
          'pr_title': pr_data['title'],
          'changed_atoms': [sanitize_atom_for_ai(a) for a in atoms[:20]],  # Limit
          'downstream_count': len(pr_data.get('downstream_atoms', [])),
          'affected_modules': pr_data.get('affected_modules', [])[:10]  # Limit
      }

      json_str = json.dumps(context)

      # Rough token estimate (1 token â‰ˆ 4 chars)
      if len(json_str) > MAX_TOKENS * 4:
          # Further truncation
          context['changed_atoms'] = context['changed_atoms'][:10]

      return json.dumps(context, indent=2)
  ```

  ## Prompt Template (per claude.md)

  ```python
  IMPACT_ANALYSIS_PROMPT = """Context: {context}
  Change: {change_description}

  Task: Provide a JSON object with keys:
  - summary (string): One paragraph explaining the change impact
  - risk_level (string): LOW | MEDIUM | HIGH | CRITICAL
  - affected_modules (array): Module IDs impacted by this change
  - suggested_reviewers (array): Usernames who should review (based on module ownership)
  - downstream_effects (number): Estimated number of atoms affected

  Rules:
  - Use CRITICAL only if > 50 atoms affected or authentication/security changes
  - Use HIGH if > 20 atoms affected or core functionality changes
  - Use MEDIUM if > 5 atoms affected
  - Use LOW otherwise
  - Suggest max 3 reviewers

  Only return valid JSON. No markdown, no explanation.
  """

  def analyze_pr_impact(pr_data: dict) -> dict:
      context = build_context(pr_data['atoms'], pr_data)
      change_desc = pr_data['title']

      prompt = IMPACT_ANALYSIS_PROMPT.format(
          context=context,
          change_description=change_desc
      )

      try:
          response = call_claude(prompt)
          return parse_json_response(response)
      except Exception as e:
          log_error(e)
          return fallback_analysis(pr_data)
  ```

  ## Fallback Mechanism

  ```python
  def fallback_analysis(pr_data: dict) -> dict:
      """Deterministic fallback when Claude API fails."""
      num_atoms_changed = len(pr_data.get('changed_atoms', []))
      num_downstream = len(pr_data.get('downstream_atoms', []))

      # Rule-based risk scoring
      if num_downstream > 50 or has_security_atom(pr_data):
          risk_level = "CRITICAL"
      elif num_downstream > 20:
          risk_level = "HIGH"
      elif num_downstream > 5:
          risk_level = "MEDIUM"
      else:
          risk_level = "LOW"

      # Suggest reviewers based on file ownership
      suggested_reviewers = get_codeowners_for_atoms(
          pr_data['changed_atoms']
      )[:3]

      return {
          "summary": f"Changes affect {num_atoms_changed} atoms with {num_downstream} downstream dependencies.",
          "risk_level": risk_level,
          "affected_modules": extract_modules_from_atoms(pr_data['changed_atoms']),
          "suggested_reviewers": suggested_reviewers,
          "downstream_effects": num_downstream,
          "analysis_method": "fallback"  # Indicate this was not AI-generated
      }
  ```

  ## Response Validation

  ```python
  from pydantic import BaseModel, Field, validator

  class ImpactAnalysisResponse(BaseModel):
      summary: str = Field(..., min_length=20, max_length=500)
      risk_level: Literal["LOW", "MEDIUM", "HIGH", "CRITICAL"]
      affected_modules: list[str] = Field(..., max_items=20)
      suggested_reviewers: list[str] = Field(..., max_items=5)
      downstream_effects: int = Field(..., ge=0)

      @validator('suggested_reviewers')
      def validate_reviewers(cls, reviewers):
          """Ensure reviewers exist in the organization."""
          valid_reviewers = get_org_members()
          return [r for r in reviewers if r in valid_reviewers]

  def parse_json_response(response_text: str) -> dict:
      """Parse and validate Claude's JSON response."""
      try:
          data = json.loads(response_text)
          validated = ImpactAnalysisResponse(**data)
          return validated.dict()
      except (json.JSONDecodeError, ValidationError) as e:
          raise ValueError(f"Invalid response from Claude: {e}")
  ```

  ## GitHub Actions Integration

  ```yaml
  # .github/workflows/gndp-agent.yml
  name: GNDP Agent - Impact Analysis

  on:
    pull_request:
      paths:
        - 'atoms/**'
        - 'modules/**'

  jobs:
    analyze:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v4
          with:
            fetch-depth: 0  # Full history for git diff

        - name: Set up Python
          uses: actions/setup-python@v4
          with:
            python-version: '3.10'

        - name: Install dependencies
          run: |
            pip install anthropic pyyaml pydantic requests

        - name: Run impact analysis
          env:
            CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          run: |
            python scripts/claude_helper.py \
              --pr ${{ github.event.pull_request.number }} \
              --repo ${{ github.repository }}

        - name: Post PR comment
          env:
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          run: |
            python scripts/post_pr_report.py \
              --pr ${{ github.event.pull_request.number }} \
              --report analysis_result.json
  ```

  ## PR Comment Format

  ```python
  def format_pr_comment(analysis: dict) -> str:
      """Format analysis as GitHub comment."""
      risk_emoji = {
          "LOW": "ðŸŸ¢",
          "MEDIUM": "ðŸŸ¡",
          "HIGH": "ðŸŸ ",
          "CRITICAL": "ðŸ”´"
      }

      emoji = risk_emoji[analysis['risk_level']]

      comment = f"""## Impact Analysis {emoji}

  **Risk Level**: {analysis['risk_level']}

  {analysis['summary']}

  ### Details
  - **Downstream Effects**: {analysis['downstream_effects']} atoms impacted
  - **Affected Modules**: {', '.join(analysis['affected_modules']) or 'None'}
  - **Suggested Reviewers**: {', '.join([f"@{r}" for r in analysis['suggested_reviewers']]) or 'Team default'}

  ### Approval Requirements
  {get_approval_requirements(analysis['risk_level'])}

  ---
  ðŸ¤– Generated by GNDP Agent with Claude Sonnet 4.5
  """

      return comment

  def get_approval_requirements(risk_level: str) -> str:
      """Map risk level to approval requirements."""
      requirements = {
          "CRITICAL": "- [ ] Requires 2 approvals from maintainers\n- [ ] Security team review required",
          "HIGH": "- [ ] Requires 2 approvals",
          "MEDIUM": "- [ ] Requires 1 approval",
          "LOW": "- [ ] Requires 1 approval"
      }
      return requirements.get(risk_level, "")
  ```

  ## Error Handling and Logging

  ```python
  import logging
  from functools import wraps

  logger = logging.getLogger(__name__)

  def with_error_handling(func):
      @wraps(func)
      async def wrapper(*args, **kwargs):
          try:
              return await func(*args, **kwargs)
          except anthropic.APIError as e:
              logger.error(f"Claude API error: {e}")
              # Use fallback
              return fallback_analysis(kwargs.get('pr_data'))
          except Exception as e:
              logger.exception(f"Unexpected error: {e}")
              raise

      return wrapper

  @with_error_handling
  async def analyze_pr_with_claude(pr_data: dict) -> dict:
      # Implementation
      pass
  ```

  ## Rate Limiting and Costs

  ```python
  from datetime import datetime, timedelta

  # Track API usage
  api_usage_tracker = {}

  def check_rate_limit() -> bool:
      """Ensure we don't exceed budget."""
      today = datetime.now().date()

      if today not in api_usage_tracker:
          api_usage_tracker[today] = 0

      # Limit: 1000 requests per day (adjust based on budget)
      return api_usage_tracker[today] < 1000

  def track_api_call():
      """Increment usage counter."""
      today = datetime.now().date()
      api_usage_tracker[today] = api_usage_tracker.get(today, 0) + 1

  def call_claude_with_budget(prompt: str) -> dict:
      if not check_rate_limit():
          logger.warning("Daily API limit reached, using fallback")
          return None  # Trigger fallback

      track_api_call()
      return call_claude(prompt)
  ```

metadata:
  priority: medium
  status: approved
  owner: devops-team
  reviewers:
    - backend-team
    - security-team
  created: 2025-12-18
  updated: 2025-12-18
  compliance_notes: |
    - Follows claude.md safety constraints
    - No PII sent to external API
    - Deterministic behavior for CI
upstream_ids:
  - REQ-005
  - REQ-004
downstream_ids:
  - PROC-005
  - POL-002
tags:
  - design
  - ai
  - claude
  - impact-analysis
  - github-actions
